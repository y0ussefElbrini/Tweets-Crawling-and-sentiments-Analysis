# cef_portfolio
Example data science portfolio

# Partie 1 : Algorithme de crawling de donn√©es:

![image](https://user-images.githubusercontent.com/94408863/141861457-180cea9c-9de2-4e97-9bb2-4508e3eccc5c.png)

1. vous pouvez remarquez l'utilisation de la librairie tweepy pour le web scrapping, apr√®s authentification, j'ai fait de sorte √† avoir 600 tweets en utilisant tweepy.cursor pour it√©rer sur les pages de tweeter et comme argument api.search.
2. Suite √† cela j'ai √©crit les donn√©es de chaque tweet dans un document text diff√©rent.
3. Puis j'ai essay√© de labeliser 400 des tweets un par un  selon l‚Äôinformation qu‚Äôils d√©tiennent dans chaque tweet (c'est une √©tape un peu lourde mais le r√©sultat vaut la peine üòÉ! ): 

- Opinion Positive
- Opinion N√©gative
- Opinion sous format de question
- Opinion Neutre (au sein de neutre on trouve : les opinions neutres, les opinions qui n‚Äôont pas de sens, les opinions difficile √† qualifier)
- Opinion sarcasme
- R√©p√©titif (si un tweet il a √©t√© r√©p√©t√©) : il n‚Äôy avait que 3 tweets qui on √©t√© r√©p√©t√© √† cause de l'utilisation du filtre :  ¬´ ‚Äì filter :retweets ¬ª au niveau hashtag choisi pour qu‚Äôil filtre tout les tweets qui ont √©t√© retweet√©.
- Tweets sous forme d‚Äôun lien

**Le r√©sultat √©tait comme cela :**

![image](https://user-images.githubusercontent.com/94408863/141862644-6f24403f-b1e2-4c3c-a483-858016249f76.png)

**Et dans chaque dossier on trouve plusieurs tweets sous format texte : par exemple le dossier de positives :**

![image](https://user-images.githubusercontent.com/94408863/141862694-ac3c9fb4-6ad7-435d-a9e2-86dfa98d515e.png)

# Partie 2 : Mod√®le pour pr√©dire les sentiments de tweets:

Pour cette partie j'ai choisi de construire le mod√®le de pr√©diction de deux classes de tweets (positives et n√©gatives) (parce qu‚Äôil serait difficile de travailler sur plus de classes alors que je n'ai √† ma disposition que 400 tweets, de plus une majorit√© de tweets ont comme tag "Opinion Neutre" ou autres).

j'ai choisi l'utilisation du mod√®le randomforrest, en choisissant la fonction randomsearchCV pour que l‚Äôalgorithme puisse choisir √† son tout les hyperparam√®tres optimaux du mod√®le randomforrest (randomsearchcv et plus rapide que gridsearchcv puisque la derni√®re parcours tous les param√®tre alors que la premi√®re parcours quelque param√®tres d‚Äôune mani√®re optimale)

**Donc le mod√®le est le suivant :**

![image](https://user-images.githubusercontent.com/94408863/141862866-b44a84a0-b454-40a2-a15b-a1493cc76103.png)

**Le r√©sultat est le suivant:**

![image](https://user-images.githubusercontent.com/94408863/141862906-9b98e4eb-ce5c-4aa1-93df-6ace108bb026.png)
